{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAMPLE RESTAURANT NLP - RATING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('../data/reviews_restaurant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4223903, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>categories</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pQeaRpvuhoEqudo3uymHIQ</td>\n",
       "      <td>The Empanadas House</td>\n",
       "      <td>404 E Green St</td>\n",
       "      <td>Champaign</td>\n",
       "      <td>IL</td>\n",
       "      <td>61820</td>\n",
       "      <td>40.110446</td>\n",
       "      <td>-88.233073</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>eSQ3z93DlzkpXK_H6MFEMw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love the empanadas from the Empanadas House!...</td>\n",
       "      <td>2013-04-11 18:36:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lu7vtrp_bE9PnxWfA8g4Pg</td>\n",
       "      <td>Banzai Sushi</td>\n",
       "      <td>300 John Street</td>\n",
       "      <td>Thornhill</td>\n",
       "      <td>ON</td>\n",
       "      <td>L3T 5W4</td>\n",
       "      <td>43.820492</td>\n",
       "      <td>-79.398466</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>dSTRQSeCqMTbs7l8KF_xJg</td>\n",
       "      <td>4</td>\n",
       "      <td>Been coming here since I was in grade 9 so abo...</td>\n",
       "      <td>2015-04-16 05:23:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LoRef3ChgZKbxUio-sHgQg</td>\n",
       "      <td>Amir</td>\n",
       "      <td>5252 Rue Jean Talon O</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>H4P 2A7</td>\n",
       "      <td>45.494870</td>\n",
       "      <td>-73.651904</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>schfOYW71VamTTdfzqDlXQ</td>\n",
       "      <td>2</td>\n",
       "      <td>Good food, terrible customer service.  For me ...</td>\n",
       "      <td>2013-05-29 16:24:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LoRef3ChgZKbxUio-sHgQg</td>\n",
       "      <td>Amir</td>\n",
       "      <td>5252 Rue Jean Talon O</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>H4P 2A7</td>\n",
       "      <td>45.494870</td>\n",
       "      <td>-73.651904</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>qKpkRCPk4ycbllTfFcRbNw</td>\n",
       "      <td>3</td>\n",
       "      <td>Just another nice Amir food nothing more but r...</td>\n",
       "      <td>2016-05-21 01:17:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ZkzutF0P_u0C0yTulwaHkA</td>\n",
       "      <td>Lelulos Pizzeria</td>\n",
       "      <td>311 Unity Center Rd</td>\n",
       "      <td>Plum</td>\n",
       "      <td>PA</td>\n",
       "      <td>15239</td>\n",
       "      <td>40.489996</td>\n",
       "      <td>-79.779288</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>HzeJmgXaaWxReb9scgjv5A</td>\n",
       "      <td>5</td>\n",
       "      <td>Stopped here with my wife due to the 18\" pizza...</td>\n",
       "      <td>2017-09-21 02:19:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 name                address  \\\n",
       "0  pQeaRpvuhoEqudo3uymHIQ  The Empanadas House         404 E Green St   \n",
       "1  lu7vtrp_bE9PnxWfA8g4Pg         Banzai Sushi        300 John Street   \n",
       "2  LoRef3ChgZKbxUio-sHgQg                 Amir  5252 Rue Jean Talon O   \n",
       "3  LoRef3ChgZKbxUio-sHgQg                 Amir  5252 Rue Jean Talon O   \n",
       "4  ZkzutF0P_u0C0yTulwaHkA     Lelulos Pizzeria    311 Unity Center Rd   \n",
       "\n",
       "        city state postal_code   latitude  longitude  stars   categories  \\\n",
       "0  Champaign    IL       61820  40.110446 -88.233073    4.5  Restaurants   \n",
       "1  Thornhill    ON     L3T 5W4  43.820492 -79.398466    4.5  Restaurants   \n",
       "2  MontrÃ©al    QC     H4P 2A7  45.494870 -73.651904    3.0  Restaurants   \n",
       "3  MontrÃ©al    QC     H4P 2A7  45.494870 -73.651904    3.0  Restaurants   \n",
       "4       Plum    PA       15239  40.489996 -79.779288    4.0  Restaurants   \n",
       "\n",
       "                  user_id  review_stars  \\\n",
       "0  eSQ3z93DlzkpXK_H6MFEMw             5   \n",
       "1  dSTRQSeCqMTbs7l8KF_xJg             4   \n",
       "2  schfOYW71VamTTdfzqDlXQ             2   \n",
       "3  qKpkRCPk4ycbllTfFcRbNw             3   \n",
       "4  HzeJmgXaaWxReb9scgjv5A             5   \n",
       "\n",
       "                                                text                 date  \n",
       "0  I love the empanadas from the Empanadas House!...  2013-04-11 18:36:15  \n",
       "1  Been coming here since I was in grade 9 so abo...  2015-04-16 05:23:15  \n",
       "2  Good food, terrible customer service.  For me ...  2013-05-29 16:24:17  \n",
       "3  Just another nice Amir food nothing more but r...  2016-05-21 01:17:33  \n",
       "4  Stopped here with my wife due to the 18\" pizza...  2017-09-21 02:19:14  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5000 rows and separate only by rating (y) and text (X)\n",
    "\n",
    "y = raw.loc[:10000,'review_stars']\n",
    "X = raw.loc[:10000,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_lookups_data\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser']) \n",
    "nlp.max_length = 33000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to clean text and obtain lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO EDIT\n",
    "def clean_url(str_text_raw):\n",
    "    '''This function eliminate a string URL in a given text'''\n",
    "    str_text = re.sub('url_\\S+', '', str_text_raw)\n",
    "    str_text = re.sub('email_\\S+', '', str_text)\n",
    "    str_text = re.sub('phone_\\S+', '', str_text)\n",
    "    return(re.sub('http[s]?://\\S+', '', str_text))\n",
    "    \n",
    "def clean_punctuation(str_text_raw):\n",
    "    '''This function replace some of the troublemaker puntuation elements in a given text'''\n",
    "    return(re.sub('[$\\(\\)/|{|\\}#~\\[\\]^#;:!?¿]', ' ', str_text_raw))\n",
    "\n",
    "def clean_unicode(str_text_raw):\n",
    "    '''This function eliminate non-unicode text'''\n",
    "    str_text = re.sub('&amp;', '', str_text_raw)\n",
    "    return(re.sub(r'[^\\x00-\\x7F]+',' ', str_text))\n",
    "                      \n",
    "def clean_dot_words(str_text_raw):\n",
    "    '''This function replace the dots between words'''\n",
    "    return(re.sub(r'(\\w+)\\.+(\\w+)', r'\\1 \\2',str_text_raw))\n",
    "\n",
    "def clean_text(str_text_raw):\n",
    "    '''This function clean a given '''\n",
    "    str_text = str_text_raw.lower()\n",
    "    str_text = clean_dot_words(clean_punctuation(clean_unicode(clean_url(str_text))))\n",
    "    return(str_text)\n",
    "\n",
    "####\n",
    "\n",
    "tokens_to_drop=['+']\n",
    "\n",
    "def string_to_token(string, str_pickle = None):\n",
    "    '''\n",
    "    This function takes a sentence and returns the list of tokens and all their information\n",
    "    * Text: The original text of the lexeme.\n",
    "    * Lemme: Lexeme.\n",
    "    * Orth: The hash value of the lexeme.\n",
    "    * is alpha: Does the lexeme consist of alphabetic characters?\n",
    "    * is digit: Does the lexeme consist of digits?\n",
    "    * is_title: Is the token in titlecase? \n",
    "    * is_punct: Is the token punctuation?\n",
    "    * is_space: Does the token consist of whitespace characters?\n",
    "    * is_stop: Is the token part of a “stop list”?\n",
    "    * is_digit: Does the token consist of digits?\n",
    "    * lang: Language of the token\n",
    "    * tag: Fine-grained part-of-speech. The complete list is in: \n",
    "    https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html, also using: spacy.explain(\"RB\")\n",
    "    * pos: Coarse-grained part-of-speech.\n",
    "    * has_vector: A boolean value indicating whether a word vector is associated with the token.\n",
    "    * vector_norm: The L2 norm of the token’s vector representation.\n",
    "    * is_ovv: '''\n",
    "    doc = nlp(string)\n",
    "    l_token = [[token.text, token.lemma_, token.orth, token.is_alpha, token.is_digit, token.is_title, token.lang_, \n",
    "        token.tag_, token.pos_, token.has_vector, token.vector_norm, token.is_oov]\n",
    "        for token in doc if not token.is_punct | token.is_space | token.is_stop | token.is_digit | token.like_url \n",
    "               | token.like_num | token.like_email & token.is_oov]\n",
    "    pd_token = pd.DataFrame(l_token, columns=['text', 'lemme', 'orth', 'is_alpha', 'is_digit', 'is_title', 'language',\n",
    "                                          'tag', 'part_of_speech', 'has_vector', 'vector_norm', 'is_oov'])\n",
    "    #drop problematic tokens\n",
    "    pd_token = pd_token[~pd_token['text'].isin(tokens_to_drop)]\n",
    "    #Convert plural text to singular\n",
    "    pd_token['text_to_singular'] = np.where(pd_token['tag'].isin(['NNPS', 'NNS']), pd_token['lemme'], pd_token['text'])\n",
    "    if(str_pickle!=None):\n",
    "        pd_token.to_pickle(f'data/pickles/{str_pickle}.pkl') #Modified\n",
    "    del l_token\n",
    "    return(pd_token)\n",
    "\n",
    "def apply_cleaning(string):\n",
    "    '''\n",
    "    This function takes a sentence and returns a clean text\n",
    "    '''\n",
    "    doc = nlp(clean_text(string))\n",
    "    l_token = [token.text for token in doc if not token.is_punct | token.is_space | token.is_stop | \n",
    "               token.is_digit | token.like_url | token.like_num | token.like_email & token.is_oov]\n",
    "    return ' '.join(l_token)\n",
    "\n",
    "def apply_lemma(string):\n",
    "    '''\n",
    "    This function takes a sentence and returns a clean text\n",
    "    '''\n",
    "    doc = nlp(clean_text(string))\n",
    "    l_token = [token.lemma_ for token in doc if not token.is_punct | token.is_space | token.is_digit | \n",
    "               token.like_url | token.like_num | token.like_email & token.is_oov]\n",
    "    return ' '.join(l_token)\n",
    "\n",
    "def list_to_bow(l_words):\n",
    "    '''\n",
    "    This function takes a list of words and create the bag of words ordered by desc order\n",
    "    '''\n",
    "    cv = CountVectorizer(l_words)\n",
    "    # show resulting vocabulary; the numbers are not counts, they are the position in the sparse vector.\n",
    "    count_vector=cv.fit_transform(l_words)\n",
    "    word_freq = Counter(l_words)\n",
    "    print(f'Bag of words size: {count_vector.shape}\\nUnique words size: {len(word_freq)}')\n",
    "    dict_word_freq = dict(word_freq.most_common())\n",
    "    return(dict_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: apply_lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:20].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\").fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "embedding = umap.UMAP(metric='hellinger', random_state=42).fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de los embbeding a positivos\n",
    "embedding_positive = embedding+5\n",
    "embedding_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_umap = pd.DataFrame(embedding_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_umap, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_report(model, X_train, X_test, y_train, y_test, name):\n",
    "    #ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy     = np.mean(cross_val_score(model, X_train, y_train, scoring='accuracy'))\n",
    "    #precision    = np.mean(cross_val_score(model, X_train, y_train, cv=ss, scoring='precision', average='micro'))\n",
    "    #recall       = np.mean(cross_val_score(model, X_train, y_train, cv=ss, scoring='recall'))\n",
    "    #f1score      = np.mean(cross_val_score(model, X_train, y_train, cv=ss, scoring='f1'))\n",
    "    #rocauc       = np.mean(cross_val_score(model, X_train, y_train, cv=ss, scoring='roc_auc'))\n",
    "    #y_pred = model.predict(X_test)\n",
    "\n",
    "    df_model = pd.DataFrame({'model'        : [name],\n",
    "                             'accuracy'     : [accuracy],\n",
    "                             #'precision'    : [precision],\n",
    "                             #'recall'       : [recall],\n",
    "                             #'f1score'      : [f1score],\n",
    "                             #'rocauc'       : [rocauc]\n",
    "                            })   \n",
    "    return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'gnb': GaussianNB(),\n",
    "          'bnb': BernoulliNB(),\n",
    "          'mnb': MultinomialNB(),\n",
    "          'logit': LogisticRegression(multi_class='auto', solver='lbfgs'),\n",
    "          'knn': KNeighborsClassifier(),\n",
    "          'decisiontree': DecisionTreeClassifier(),\n",
    "          'randomforest': RandomForestClassifier(),\n",
    "          'svc': SVC(probability=True),\n",
    "          'linearsvc': LinearSVC(),\n",
    "          'xgboost': GradientBoostingClassifier(),\n",
    "          'NN': MLPClassifier()\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "# Cross-validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.concat([baseline_report(model, X_train, X_test, y_train, y_test, name) \n",
    "                       for (name, model) in models.items()])\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "#model.fit(X_train, y_train)\n",
    "accuracy     = np.mean(cross_val_score(rf, X_train, y_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
